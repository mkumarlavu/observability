# This file completely replaces the default config
# Must include ALL existing functionality + new log configuration

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:9317
      http:
        endpoint: 0.0.0.0:9318
    tls:
      cert_file:  "/tmp/ssl/certs/tls.crt"
      key_file:   "/tmp/ssl/certs/tls.key"

  prometheus/self-monitoring:
    config:
      scrape_configs:
        - job_name: "opentelemetry-collector"
          scrape_interval: 60s
          static_configs:
            - targets: ["localhost:9319"]
          relabel_configs:
            - action: replace
              target_label: instance
              replacement: '{{ include "opentelemetry-collector.service.instance.id" . }}'

  # NEW: Add log receiver
  filelog:
    include: 
      - /var/log/pods/*/*/*.log
    exclude:
      - /var/log/pods/*/opentelemetry*/*.log
    operators:
      - type: json_parser
        id: parser-docker
        output: extract_metadata_from_filepath
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      - type: regex_parser
        id: extract_metadata_from_filepath
        regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
        parse_from: attributes["log.file.path"]
        parse_to: attributes["log.file.path_parsed"]
      - type: move
        from: attributes["log.file.path_parsed"]["namespace"]
        to: resource["k8s.namespace.name"]
      - type: move
        from: attributes["log.file.path_parsed"]["pod_name"]
        to: resource["k8s.pod.name"]
      - type: move
        from: attributes["log.file.path_parsed"]["container_name"]
        to: resource["k8s.container.name"]

processors:
  memory_limiter:
    check_interval:       1s
    limit_percentage:     70
    spike_limit_percentage: 14
  batch:
    send_batch_max_size: 8192
    timeout:            5s

exporters:
  logging:
    verbosity: detailed

  # Keep existing CloudWatch metrics exporter
  awsemf/self-monitoring:
    namespace: EKS/OpenTelemetry
    dimension_rollup_option: NoDimensionRollup
    resource_to_telemetry_conversion:
      enabled: true
    log_group_name: /aws/eks/otel-collector  # You'll need to set this value
    log_stream_name: "$(INFO_KUBE_POD_NAME)-self-monitoring"
    metric_declarations:
      - metric_name_selectors: ["^otelcol_process_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment"]
      - metric_name_selectors: ["^otelcol_exporter_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","exporter"]
      - metric_name_selectors: ["^otelcol_processor_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","processor"]
      - metric_name_selectors: ["^otelcol_receiver_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","receiver"]

  awsemf:
    namespace: Application/OpenTelemetry
    dimension_rollup_option: NoDimensionRollup
    log_group_name: /aws/eks/application-metrics  # You'll need to set this value
    log_stream_name: "$(INFO_KUBE_POD_NAME)-app-metrics"

  # Keep existing X-Ray exporter
  awsxray:
    index_all_attributes: true

  # NEW: Add CloudWatch Logs exporter
  awscloudwatchlogs:
    log_group_name: /aws/eks/application-logs
    log_stream_name: "$(INFO_KUBE_NODE_NAME)/$(INFO_KUBE_POD_NAME)"

extensions:
  memory_ballast:
    size_in_percentage: 30

service:
  # Keep existing pipelines
  pipelines/self-monitoring:
    receivers:  [prometheus/self-monitoring]
    processors: [batch]
    exporters:  [logging, awsemf/self-monitoring]

  metrics:
    receivers:  [otlp]
    processors: [batch]
    exporters:  [logging, awsemf]

  traces:
    receivers:  [otlp]
    processors: [batch]
    exporters:  [logging, awsxray]

  # NEW: Add logs pipeline
  logs:
    receivers:  [filelog]
    processors: [memory_limiter, batch]
    exporters:  [logging, awscloudwatchlogs]

telemetry:
  logs:
    level: info  # You'll need to set this value
  metrics:
    level:   detailed
    address: localhost:9319

extensions: [memory_ballast]


=======================================================

# OpenTelemetry Collector Configuration
# Complete configuration with logs, metrics, and traces

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:9317
      http:
        endpoint: 0.0.0.0:9318
    tls:
      cert_file: "/tmp/ssl/certs/tls.crt"
      key_file: "/tmp/ssl/certs/tls.key"

  prometheus/self-monitoring:
    config:
      scrape_configs:
        - job_name: "opentelemetry-collector"
          scrape_interval: 60s
          static_configs:
            - targets: ["localhost:9319"]
          relabel_configs:
            - action: replace
              target_label: instance
              replacement: 'otel-collector-instance'

  # Log receiver for Kubernetes pod logs
  filelog:
    include: 
      - /var/log/pods/*/*/*.log
    exclude:
      - /var/log/pods/*/opentelemetry*/*.log
    operators:
      - type: json_parser
        id: parser-docker
        output: extract_metadata_from_filepath
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      - type: regex_parser
        id: extract_metadata_from_filepath
        regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
        parse_from: attributes["log.file.path"]
        parse_to: attributes["log.file.path_parsed"]
      - type: move
        from: attributes["log.file.path_parsed"]["namespace"]
        to: resource["k8s.namespace.name"]
      - type: move
        from: attributes["log.file.path_parsed"]["pod_name"]
        to: resource["k8s.pod.name"]
      - type: move
        from: attributes["log.file.path_parsed"]["container_name"]
        to: resource["k8s.container.name"]

processors:
  memory_limiter:
    check_interval: 1s
    limit_percentage: 70
    spike_limit_percentage: 14
  
  batch:
    send_batch_max_size: 8192
    timeout: 5s

exporters:
  logging:
    verbosity: detailed

  # CloudWatch metrics exporter for self-monitoring
  awsemf/self-monitoring:
    namespace: EKS/OpenTelemetry
    dimension_rollup_option: NoDimensionRollup
    resource_to_telemetry_conversion:
      enabled: true
    log_group_name: /aws/eks/otel-collector
    log_stream_name: "$(INFO_KUBE_POD_NAME)-self-monitoring"
    metric_declarations:
      - metric_name_selectors: ["^otelcol_process_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment"]
      - metric_name_selectors: ["^otelcol_exporter_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","exporter"]
      - metric_name_selectors: ["^otelcol_processor_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","processor"]
      - metric_name_selectors: ["^otelcol_receiver_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","receiver"]

  # CloudWatch metrics exporter for application metrics
  awsemf:
    namespace: Application/OpenTelemetry
    dimension_rollup_option: NoDimensionRollup
    log_group_name: /aws/eks/application-metrics
    log_stream_name: "$(INFO_KUBE_POD_NAME)-app-metrics"

  # X-Ray exporter for traces
  awsxray:
    index_all_attributes: true

  # CloudWatch Logs exporter
  awscloudwatchlogs:
    log_group_name: /aws/eks/application-logs
    log_stream_name: "$(INFO_KUBE_NODE_NAME)/$(INFO_KUBE_POD_NAME)"

extensions:
  memory_ballast:
    size_in_percentage: 30

service:
  pipelines:
    self-monitoring:
      receivers: [prometheus/self-monitoring]
      processors: [batch]
      exporters: [logging, awsemf/self-monitoring]

    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, awsemf]

    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, awsxray]

    logs:
      receivers: [filelog]
      processors: [memory_limiter, batch]
      exporters: [logging, awscloudwatchlogs]

  telemetry:
    logs:
      level: info
    metrics:
      level: detailed
      address: localhost:9319

  extensions: [memory_ballast]



====================================NO TLS=========================================

receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:9317
      http:
        endpoint: 0.0.0.0:9318

  prometheus/self-monitoring:
    config:
      scrape_configs:
        - job_name: "opentelemetry-collector"
          scrape_interval: 60s
          static_configs:
            - targets: ["localhost:9319"]
          relabel_configs:
            - action: replace
              target_label: instance
              replacement: 'otel-collector-instance'

  filelog:
    include: 
      - /var/log/pods/*/*/*.log
    exclude:
      - /var/log/pods/*/opentelemetry*/*.log
    operators:
      - type: json_parser
        id: parser-docker
        output: extract_metadata_from_filepath
        timestamp:
          parse_from: attributes.time
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
      - type: regex_parser
        id: extract_metadata_from_filepath
        regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]+)\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
        parse_from: attributes["log.file.path"]
        parse_to: attributes["log.file.path_parsed"]
      - type: move
        from: attributes["log.file.path_parsed"]["namespace"]
        to: resource["k8s.namespace.name"]
      - type: move
        from: attributes["log.file.path_parsed"]["pod_name"]
        to: resource["k8s.pod.name"]
      - type: move
        from: attributes["log.file.path_parsed"]["container_name"]
        to: resource["k8s.container.name"]

processors:
  memory_limiter:
    check_interval: 1s
    limit_percentage: 70
    spike_limit_percentage: 14
  
  batch:
    send_batch_max_size: 8192
    timeout: 5s

exporters:
  logging:
    verbosity: detailed

  awsemf/self-monitoring:
    namespace: EKS/OpenTelemetry
    dimension_rollup_option: NoDimensionRollup
    resource_to_telemetry_conversion:
      enabled: true
    log_group_name: /aws/eks/otel-collector
    log_stream_name: "$(INFO_KUBE_POD_NAME)-self-monitoring"
    metric_declarations:
      - metric_name_selectors: ["^otelcol_process_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment"]
      - metric_name_selectors: ["^otelcol_exporter_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","exporter"]
      - metric_name_selectors: ["^otelcol_processor_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","processor"]
      - metric_name_selectors: ["^otelcol_receiver_.+$"]
        dimensions:
          - ["service.name","service.instance.id","service_version","deployment_location","deployment_environment","receiver"]

  awsemf:
    namespace: Application/OpenTelemetry
    dimension_rollup_option: NoDimensionRollup
    log_group_name: /aws/eks/application-metrics
    log_stream_name: "$(INFO_KUBE_POD_NAME)-app-metrics"

  awsxray:
    index_all_attributes: true

  awscloudwatchlogs:
    log_group_name: /aws/eks/application-logs
    log_stream_name: "$(INFO_KUBE_NODE_NAME)/$(INFO_KUBE_POD_NAME)"

extensions:
  memory_ballast:
    size_in_percentage: 30

service:
  pipelines:
    self-monitoring:
      receivers: [prometheus/self-monitoring]
      processors: [batch]
      exporters: [logging, awsemf/self-monitoring]

    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, awsemf]

    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [logging, awsxray]

    logs:
      receivers: [filelog]
      processors: [memory_limiter, batch]
      exporters: [logging, awscloudwatchlogs]

  telemetry:
    logs:
      level: info
    metrics:
      level: detailed
      address: localhost:9319

  extensions: [memory_ballast]







# Check if your custom config was applied
#kubectl get opentelemetrycollector -n opentelemetry-system

# Describe the collector to see your custom config
#kubectl describe opentelemetrycollector opentelemetry -n opentelemetry-system

===>
# Check collector logs for any errors
kubectl logs -n opentelemetry-system -l app.kubernetes.io/name=opentelemetry-collector

# Look for:
# ✅ "Everything is ready. Begin running and processing data."
# ✅ Log receivers, processors, exporters starting
# ❌ Any error messages about config or connections



# Check if the filelog receiver is working
kubectl logs -n opentelemetry-system -l app.kubernetes.io/name=opentelemetry-collector | grep -i "filelog\|log"

# Should see messages about log files being read
# "containers-read.gkp.jpmchase.net/container-release/kubecharts/opentelemetry-operator:0.89.0-0.0.2"
